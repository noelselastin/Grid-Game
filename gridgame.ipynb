{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 15.420482158660889 seconds\n",
      "Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Board definition\n",
    "# 0-Path, 1-Origin, 2-hole, 3-goal\n",
    "board1 = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 3],\n",
    "    [0, 0, 2, 2, 2],\n",
    "    [0, 2, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "selected_board = board1\n",
    "\n",
    "# Extract start, end, and hole positions\n",
    "start_pos = np.argwhere(selected_board == 1)[0]\n",
    "end_pos = np.argwhere(selected_board == 3)[0]\n",
    "hole_pos = np.argwhere(selected_board == 2)\n",
    "\n",
    "# State initialization\n",
    "state = start_pos.tolist()\n",
    "\n",
    "# Actions: up-0, right-1, down-2, left-3\n",
    "action_map = np.array([[-1, 0], [0, 1], [1, 0], [0, -1]])\n",
    "\n",
    "def do_action(state, action):\n",
    "    next_state = state + action_map[action]\n",
    "    reward = 0\n",
    "    running = True\n",
    "\n",
    "    # Check for grid boundaries\n",
    "    if not (0 <= next_state[0] < 5 and 0 <= next_state[1] < 5):\n",
    "        next_state = state\n",
    "    elif list(next_state) in hole_pos.tolist():\n",
    "        reward = -1\n",
    "        running = False\n",
    "    elif list(next_state) == end_pos.tolist():\n",
    "        reward = 1\n",
    "        running = False\n",
    "\n",
    "    return next_state, reward, running\n",
    "\n",
    "def state_no(state):\n",
    "    return state[0] * 5 + state[1]\n",
    "\n",
    "def reset():\n",
    "    return start_pos.copy(), True, 1\n",
    "\n",
    "# Q-table initialization\n",
    "Q = np.zeros([25, 4])\n",
    "\n",
    "# Learning parameters\n",
    "alpha = 0.8\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.9995\n",
    "min_epsilon = 0.01\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "\n",
    "# Replay buffer\n",
    "replay_buffer = deque(maxlen=20000)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for x in range(epochs):\n",
    "    state, game_running, no_of_actions = reset()\n",
    "    while game_running and no_of_actions < 200:\n",
    "        rand_number = np.random.uniform(0, 1)\n",
    "        if rand_number < epsilon:\n",
    "            # Precompute valid actions based on current state\n",
    "            valid_actions = [i for i in range(4) if (0 <= state[0] + action_map[i][0] < 5 and 0 <= state[1] + action_map[i][1] < 5)]\n",
    "            action = random.choice(valid_actions)\n",
    "        else:\n",
    "            action = np.argmax(Q[state_no(state), :])\n",
    "\n",
    "        next_state, action_reward, game_running = do_action(state, action)\n",
    "        next_state_number = state_no(next_state)\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        replay_buffer.append((state_no(state), action, action_reward, next_state_number, game_running))\n",
    "\n",
    "        # Update Q-table\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            minibatch = random.sample(replay_buffer, batch_size)\n",
    "            state_nos, actions, rewards, next_state_nos, runnings = zip(*minibatch)\n",
    "            state_nos = np.array(state_nos)\n",
    "            actions = np.array(actions)\n",
    "            rewards = np.array(rewards)\n",
    "            next_state_nos = np.array(next_state_nos)\n",
    "            runnings = np.array(runnings, dtype=int)\n",
    "\n",
    "            target_Qs = rewards + gamma * np.max(Q[next_state_nos, :], axis=1) * runnings\n",
    "            Q[state_nos, actions] += alpha * (target_Qs - Q[state_nos, actions])\n",
    "\n",
    "        state = next_state\n",
    "        no_of_actions += 1\n",
    "\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "# Accuracy calculation\n",
    "q_action_values = np.zeros((5, 5), dtype=int)\n",
    "for m in range(5):\n",
    "    for n in range(5):\n",
    "        q_action_values[m, n] = np.argmax(Q[state_no([m, n]), :])\n",
    "\n",
    "best_action_values = np.array([\n",
    "    [[2,1], [2,1], [2,1], [2, 1], [2]],\n",
    "    [[1], [1], [1], [1], [4]],\n",
    "    [[0,1], [0], [4], [4], [4]],\n",
    "    [[0], [4], [2], [2], [2]],\n",
    "    [[0], [3], [3], [3], [3]]\n",
    "], dtype=object)\n",
    "# Actions: up-0, right-1, down-2, left-3\n",
    "\n",
    "accuracy = 0\n",
    "for m in range(5):\n",
    "    for n in range(5):\n",
    "        if q_action_values[m, n] in best_action_values[m, n]:\n",
    "            accuracy += 1\n",
    "\n",
    "accuracy_percentage = (accuracy / 20) * 100\n",
    "print(\"Accuracy =\", accuracy_percentage, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying predicted directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\tright\tright\tright\tdown\t\n",
      "right\tright\tright\tright\tup\t\n",
      "up\tup\tup\tup\tup\t\n",
      "up\tup\tdown\tdown\tdown\t\n",
      "up\tleft\tleft\tleft\tleft\t\n"
     ]
    }
   ],
   "source": [
    "maximum=0\n",
    "ind=0\n",
    "l=[]\n",
    "for i in range(25):\n",
    "    l=list(Q[i,:])\n",
    "    maximum=max(l)\n",
    "    ind=l.index(maximum)\n",
    "    if ind==0:\n",
    "        print('up\\t',end=\"\")\n",
    "    if ind==1:\n",
    "        print('right\\t',end=\"\")\n",
    "    if ind==2:\n",
    "        print('down\\t',end=\"\")\n",
    "    if ind==3:\n",
    "        print('left\\t',end=\"\")\n",
    "    if (i+1)%5==0:\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
